# Silicon Memory - Implementation Plan

## Executive Summary

Silicon Memory is a multi-layered cognitive memory system for LLM augmentation. The core storage layer is complete, backed by SiliconDB. This plan outlines the remaining work to make it production-ready.

**Current State**: Core memory system functional (semantic, episodic, procedural, working)
**Remaining Work**: Reflection engine, graph queries, LLM integrations, examples

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Applications                              â”‚
â”‚   (Agents, Chatbots, Knowledge Systems, Research Assistants)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     LLM Integration Layer                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ MemoryTool   â”‚  â”‚ QueryTool    â”‚  â”‚ ReflectionEngine     â”‚   â”‚
â”‚  â”‚ (store/recall)â”‚  â”‚ (what do you â”‚  â”‚ (experienceâ†’belief)  â”‚   â”‚
â”‚  â”‚              â”‚  â”‚  know + proofs)â”‚  â”‚                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                       SiliconMemory                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚Semantic â”‚ â”‚Episodic â”‚ â”‚Procedural â”‚ â”‚Working  â”‚ â”‚ Graph   â”‚  â”‚
â”‚  â”‚(beliefs)â”‚ â”‚(events) â”‚ â”‚(how-to)   â”‚ â”‚(context)â”‚ â”‚(relations)â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     SiliconDBBackend                             â”‚
â”‚            Temporal Decay â”‚ Contradiction Detection              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        SiliconDB                                 â”‚
â”‚     mmap + WAL â”‚ Metal GPU â”‚ Auto-embedding â”‚ Graph â”‚ Beliefs   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Phase 1: Reflection Engine (Priority: High)

### Overview
The Reflection Engine processes episodic memories (experiences) and extracts semantic knowledge (beliefs). This mimics human memory consolidation during sleep.

### Components

#### 1.1 ExperienceProcessor
Analyzes unprocessed experiences to extract patterns and facts.

```python
# src/silicon_memory/reflection/processor.py

class ExperienceProcessor:
    """Processes experiences to extract beliefs and patterns.

    The processor:
    1. Fetches unprocessed experiences
    2. Groups related experiences
    3. Extracts common patterns
    4. Generates belief candidates
    5. Validates against existing knowledge
    """

    async def process_batch(
        self,
        max_experiences: int = 100,
        min_confidence: float = 0.6,
    ) -> ReflectionResult:
        """Process a batch of unprocessed experiences.

        Returns:
            ReflectionResult with:
            - new_beliefs: List of extracted beliefs
            - updated_beliefs: List of beliefs with updated confidence
            - contradictions: List of detected contradictions
            - processed_count: Number of experiences processed
        """
```

#### 1.2 PatternExtractor
Identifies patterns across multiple experiences.

```python
# src/silicon_memory/reflection/patterns.py

class PatternExtractor:
    """Extracts patterns from experience sequences.

    Patterns include:
    - Causal relationships (A causes B)
    - Temporal sequences (A followed by B)
    - Correlations (A often occurs with B)
    - Generalizations (All X have property Y)
    """

    async def extract_patterns(
        self,
        experiences: list[Experience],
        min_occurrences: int = 2,
    ) -> list[Pattern]:
        """Extract patterns from experiences."""
```

#### 1.3 BeliefGenerator
Converts patterns into belief candidates.

```python
# src/silicon_memory/reflection/generator.py

class BeliefGenerator:
    """Generates belief candidates from patterns.

    Uses LLM to:
    1. Formulate beliefs as triplets or statements
    2. Assign initial confidence based on evidence
    3. Identify potential contradictions
    """

    async def generate_beliefs(
        self,
        patterns: list[Pattern],
        existing_beliefs: list[Belief],
    ) -> list[BeliefCandidate]:
        """Generate belief candidates from patterns."""
```

### Implementation Tasks

| Task | Description | Effort |
|------|-------------|--------|
| 1.1.1 | Create `reflection/` module structure | S |
| 1.1.2 | Implement ExperienceProcessor | M |
| 1.1.3 | Implement PatternExtractor | M |
| 1.1.4 | Implement BeliefGenerator (with LLM) | L |
| 1.1.5 | Add ReflectionTool for LLM function calling | M |
| 1.1.6 | Integration tests for reflection | M |

---

## Phase 2: Graph Query Layer (Priority: High)

### Overview
Expose SiliconDB's graph capabilities for relationship traversal and entity exploration.

### Components

#### 2.1 GraphQuery API
Query interface for relationship traversal.

```python
# src/silicon_memory/graph/queries.py

class GraphQueryBuilder:
    """Fluent API for building graph queries.

    Example:
        query = (GraphQuery(memory)
            .start("Python")
            .traverse("is_used_for", depth=2)
            .filter(min_confidence=0.7)
            .limit(20))

        results = await query.execute()
    """

    def start(self, entity: str) -> "GraphQueryBuilder":
        """Start from an entity."""

    def traverse(
        self,
        edge_type: str | None = None,
        direction: str = "outgoing",
        depth: int = 1,
    ) -> "GraphQueryBuilder":
        """Traverse relationships."""

    def filter(
        self,
        min_confidence: float = 0.0,
        node_types: list[str] | None = None,
    ) -> "GraphQueryBuilder":
        """Filter results."""
```

#### 2.2 EntityExplorer
Comprehensive view of an entity and its relationships.

```python
# src/silicon_memory/graph/explorer.py

class EntityExplorer:
    """Explore entities and their relationships.

    Provides:
    - All beliefs about an entity
    - Related entities (neighbors in graph)
    - Causal chains involving the entity
    - Contradicting beliefs
    """

    async def explore(
        self,
        entity: str,
        depth: int = 2,
    ) -> EntityProfile:
        """Build comprehensive profile of an entity."""
```

### Implementation Tasks

| Task | Description | Effort |
|------|-------------|--------|
| 2.1.1 | Create `graph/` module structure | S |
| 2.1.2 | Implement GraphQueryBuilder | M |
| 2.1.3 | Implement EntityExplorer | M |
| 2.1.4 | Add GraphTool for LLM function calling | M |
| 2.1.5 | Integration tests for graph queries | M |

---

## Phase 3: LLM Client Integration (Priority: Medium)

### Overview
Provide ready-to-use clients for OpenAI and Anthropic APIs with memory integration.

### Components

#### 3.1 MemoryAugmentedClient
Base class for memory-augmented LLM clients.

```python
# src/silicon_memory/clients/base.py

class MemoryAugmentedClient:
    """Base class for memory-augmented LLM clients.

    Features:
    - Automatic context injection from memory
    - Experience recording after each interaction
    - Belief extraction from responses
    - Working memory management
    """

    def __init__(
        self,
        memory: SiliconMemory,
        auto_recall: bool = True,
        auto_record: bool = True,
    ):
        self.memory = memory
        self.memory_tool = MemoryTool(memory)
        self.query_tool = QueryTool(memory)
```

#### 3.2 OpenAI Integration

```python
# src/silicon_memory/clients/openai.py

class OpenAIMemoryClient(MemoryAugmentedClient):
    """OpenAI client with memory integration.

    Example:
        client = OpenAIMemoryClient(
            memory=memory,
            model="gpt-4",
            api_key=os.environ["OPENAI_API_KEY"],
        )

        response = await client.chat(
            messages=[{"role": "user", "content": "What is Python?"}],
            use_memory=True,  # Inject relevant context
            record_experience=True,  # Save interaction
        )
    """

    async def chat(
        self,
        messages: list[dict],
        use_memory: bool = True,
        record_experience: bool = True,
        **kwargs,
    ) -> ChatResponse:
        """Chat with memory augmentation."""
```

#### 3.3 Anthropic Integration

```python
# src/silicon_memory/clients/anthropic.py

class AnthropicMemoryClient(MemoryAugmentedClient):
    """Anthropic client with memory integration.

    Example:
        client = AnthropicMemoryClient(
            memory=memory,
            model="claude-sonnet-4-20250514",
            api_key=os.environ["ANTHROPIC_API_KEY"],
        )

        response = await client.message(
            messages=[{"role": "user", "content": "Explain machine learning"}],
            use_memory=True,
        )
    """
```

### Implementation Tasks

| Task | Description | Effort |
|------|-------------|--------|
| 3.1.1 | Create `clients/` module structure | S |
| 3.1.2 | Implement MemoryAugmentedClient base | M |
| 3.1.3 | Implement OpenAIMemoryClient | M |
| 3.1.4 | Implement AnthropicMemoryClient | M |
| 3.1.5 | Add streaming support | M |
| 3.1.6 | Integration tests with mocked APIs | M |

---

## Phase 4: DSPy Integration (Priority: Low)

### Overview
Integrate with DSPy for declarative LLM programming with memory.

### Components

#### 4.1 DSPy Modules

```python
# src/silicon_memory/dspy/modules.py

class MemoryRecall(dspy.Module):
    """DSPy module for memory recall.

    Example:
        recall = MemoryRecall(memory)
        context = recall(query="Python programming")
    """

class MemoryStore(dspy.Module):
    """DSPy module for storing to memory.

    Example:
        store = MemoryStore(memory)
        store(fact="Python was created by Guido van Rossum", confidence=0.95)
    """

class MemoryAugmentedChain(dspy.Module):
    """Chain that automatically uses memory for context.

    Example:
        chain = MemoryAugmentedChain(memory)
        response = chain(question="What is Python?")
        # Automatically recalls relevant context and stores the interaction
    """
```

### Implementation Tasks

| Task | Description | Effort |
|------|-------------|--------|
| 4.1.1 | Create `dspy/` module structure | S |
| 4.1.2 | Implement MemoryRecall module | M |
| 4.1.3 | Implement MemoryStore module | M |
| 4.1.4 | Implement MemoryAugmentedChain | L |
| 4.1.5 | Add DSPy optimizers for memory | L |

---

## Phase 5: Examples & Documentation (Priority: High)

### Overview
Create comprehensive examples showing real-world usage patterns.

### Examples to Create

#### 5.1 Basic Usage (`examples/basic_usage.py`)

```python
"""Basic usage example for Silicon Memory."""

import asyncio
from uuid import uuid4
from silicon_memory import (
    SiliconMemory,
    Belief,
    Experience,
    Procedure,
    Triplet,
    Source,
    RecallContext,
)


async def main():
    # Initialize memory system
    async with SiliconMemory("/tmp/example_memory") as memory:

        # =================================================================
        # STORING BELIEFS (Semantic Memory)
        # =================================================================

        # Create a source for attribution
        docs_source = Source(
            id="python-docs",
            type="documentation",
            name="Python Official Documentation",
            url="https://docs.python.org",
            reliability=0.95,
        )

        # Store a belief as a triplet (subject-predicate-object)
        belief1 = Belief(
            id=uuid4(),
            triplet=Triplet(
                subject="Python",
                predicate="is",
                object="programming language",
            ),
            confidence=0.95,
            source=docs_source,
            tags=["programming", "language"],
        )
        await memory.commit_belief(belief1)

        # Store a belief as free-form content
        belief2 = Belief(
            id=uuid4(),
            content="Python emphasizes code readability and simplicity.",
            confidence=0.9,
            source=docs_source,
            tags=["programming", "philosophy"],
        )
        await memory.commit_belief(belief2)

        print("âœ“ Stored 2 beliefs about Python")

        # =================================================================
        # RECORDING EXPERIENCES (Episodic Memory)
        # =================================================================

        # Record an interaction experience
        experience = Experience(
            id=uuid4(),
            content="User asked about Python's history and creator",
            outcome="Explained that Guido van Rossum created Python in 1991",
            emotional_valence=0.6,  # Positive interaction
            importance=0.7,
            session_id="demo-session",
        )
        await memory.record_experience(experience)

        print("âœ“ Recorded 1 experience")

        # =================================================================
        # STORING PROCEDURES (Procedural Memory)
        # =================================================================

        # Store a how-to procedure
        procedure = Procedure(
            id=uuid4(),
            name="Install Python Package",
            description="How to install a Python package using pip",
            steps=[
                "Open terminal or command prompt",
                "Ensure pip is installed: python -m pip --version",
                "Install package: pip install package-name",
                "Verify installation: python -c 'import package'",
            ],
            trigger="install python package pip",
            confidence=0.9,
        )
        await memory.commit_procedure(procedure)

        print("âœ“ Stored 1 procedure")

        # =================================================================
        # WORKING MEMORY (Short-term Context)
        # =================================================================

        # Set working context (expires after TTL)
        await memory.set_context("current_topic", "Python basics", ttl_seconds=300)
        await memory.set_context("user_level", "beginner", ttl_seconds=300)

        # Retrieve context
        topic = await memory.get_context("current_topic")
        print(f"âœ“ Working context set: topic={topic}")

        # =================================================================
        # RECALLING MEMORIES
        # =================================================================

        # Recall relevant memories across all types
        ctx = RecallContext(
            query="Python programming basics",
            max_facts=10,
            max_experiences=5,
            max_procedures=3,
            min_confidence=0.5,
        )

        response = await memory.recall(ctx)

        print(f"\nðŸ“š Recall Results for '{ctx.query}':")
        print(f"   Facts: {len(response.facts)}")
        print(f"   Experiences: {len(response.experiences)}")
        print(f"   Procedures: {len(response.procedures)}")
        print(f"   Working context: {response.working_context}")

        # =================================================================
        # KNOWLEDGE PROOFS ("What do you know?")
        # =================================================================

        # Ask what the system knows about a topic
        proof = await memory.what_do_you_know("Python")

        print(f"\nðŸ§  Knowledge Proof for 'Python':")
        print(f"   Total confidence: {proof.total_confidence:.0%}")
        print(f"   Beliefs found: {len(proof.beliefs)}")
        print(f"   Sources: {len(proof.sources)}")
        print(f"   Contradictions: {len(proof.contradictions)}")

        # Print the formatted report
        print("\n" + "=" * 50)
        print(proof.as_report())


if __name__ == "__main__":
    asyncio.run(main())
```

#### 5.2 LLM Tool Integration (`examples/llm_tools.py`)

```python
"""Example: Using Silicon Memory as LLM function tools."""

import asyncio
import json
from silicon_memory import SiliconMemory, MemoryTool, QueryTool


async def main():
    async with SiliconMemory("/tmp/llm_tools_example") as memory:

        # Create tools
        memory_tool = MemoryTool(memory)
        query_tool = QueryTool(memory)

        # =================================================================
        # GET OPENAI FUNCTION SCHEMA
        # =================================================================

        schema = MemoryTool.get_openai_schema()
        print("OpenAI Function Schema:")
        print(json.dumps(schema, indent=2))

        # =================================================================
        # SIMULATE LLM FUNCTION CALLS
        # =================================================================

        # LLM decides to store a fact
        response = await memory_tool.invoke(
            action="store_fact",
            subject="Machine Learning",
            predicate="is a subset of",
            object="Artificial Intelligence",
            confidence=0.95,
            tags=["ml", "ai"],
        )
        print(f"\nâœ“ store_fact: {response.data}")

        # LLM stores an experience
        response = await memory_tool.invoke(
            action="store_experience",
            content="Explained ML vs AI distinction to user",
            outcome="User understood the relationship",
            importance=0.7,
        )
        print(f"âœ“ store_experience: {response.data}")

        # LLM recalls relevant context
        response = await memory_tool.invoke(
            action="recall",
            query="machine learning artificial intelligence",
            max_facts=5,
        )
        print(f"âœ“ recall: found {response.data['total_items']} items")

        # LLM asks what it knows
        response = await memory_tool.invoke(
            action="what_do_you_know",
            query="AI and ML",
        )
        print(f"âœ“ what_do_you_know: {response.data['belief_count']} beliefs")
        print(f"\nReport:\n{response.data['report']}")

        # =================================================================
        # USING QUERY TOOL FOR VERIFICATION
        # =================================================================

        # Verify a claim
        result = await query_tool.verify_claim(
            "Machine Learning is part of AI",
            min_confidence=0.5,
        )
        print(f"\nðŸ” Claim verification:")
        print(f"   Status: {result['status']}")
        print(f"   Score: {result['verification_score']:.2f}")
        print(f"   Supporting beliefs: {result['supporting_beliefs']}")


if __name__ == "__main__":
    asyncio.run(main())
```

#### 5.3 Knowledge Base Building (`examples/knowledge_base.py`)

```python
"""Example: Building a knowledge base from documents."""

import asyncio
from uuid import uuid4
from silicon_memory import (
    SiliconMemory,
    Belief,
    Triplet,
    Source,
)


# Sample knowledge to ingest
PYTHON_FACTS = [
    ("Python", "was created by", "Guido van Rossum"),
    ("Python", "was first released in", "1991"),
    ("Python", "is known for", "readability"),
    ("Python", "supports", "multiple programming paradigms"),
    ("Python", "has", "dynamic typing"),
    ("Python", "uses", "indentation for code blocks"),
    ("Python 3", "was released in", "2008"),
    ("Python 2", "reached end of life in", "2020"),
    ("pip", "is", "Python package manager"),
    ("PyPI", "is", "Python Package Index"),
    ("Django", "is", "Python web framework"),
    ("Flask", "is", "Python micro web framework"),
    ("NumPy", "is used for", "numerical computing in Python"),
    ("Pandas", "is used for", "data analysis in Python"),
    ("TensorFlow", "is", "machine learning framework for Python"),
    ("PyTorch", "is", "machine learning framework for Python"),
]


async def main():
    async with SiliconMemory("/tmp/knowledge_base_example") as memory:

        # Create source
        source = Source(
            id="python-knowledge",
            type="curated",
            name="Python Knowledge Base",
            reliability=0.9,
        )

        # =================================================================
        # INGEST KNOWLEDGE
        # =================================================================

        print("Ingesting Python knowledge base...")

        for subject, predicate, obj in PYTHON_FACTS:
            belief = Belief(
                id=uuid4(),
                triplet=Triplet(subject=subject, predicate=predicate, object=obj),
                confidence=0.9,
                source=source,
                tags=["python"],
            )
            await memory.commit_belief(belief)

        print(f"âœ“ Ingested {len(PYTHON_FACTS)} facts")

        # =================================================================
        # QUERY THE KNOWLEDGE BASE
        # =================================================================

        queries = [
            "Python history creator",
            "Python web frameworks",
            "machine learning Python",
            "Python package management",
        ]

        for query in queries:
            proof = await memory.what_do_you_know(query)

            print(f"\nðŸ“š Query: '{query}'")
            print(f"   Found {len(proof.beliefs)} relevant beliefs")

            for belief in proof.beliefs[:3]:
                if belief.triplet:
                    print(f"   â€¢ {belief.triplet.subject} {belief.triplet.predicate} {belief.triplet.object}")
                else:
                    print(f"   â€¢ {belief.content[:50]}...")

        # =================================================================
        # FIND CONTRADICTIONS
        # =================================================================

        # Add a potentially contradicting belief
        contradicting = Belief(
            id=uuid4(),
            triplet=Triplet("Python", "was first released in", "1989"),  # Wrong!
            confidence=0.5,
            source=Source(id="unreliable", type="web", name="Random Blog", reliability=0.3),
        )
        await memory.commit_belief(contradicting)

        # Check for contradictions
        proof = await memory.what_do_you_know("Python release date")

        print(f"\nâš ï¸ Contradiction check:")
        print(f"   Contradictions found: {len(proof.contradictions)}")

        for b1, b2 in proof.contradictions:
            t1 = b1.triplet
            t2 = b2.triplet
            if t1 and t2:
                print(f"   â€¢ '{t1.object}' vs '{t2.object}' (confidence: {b1.confidence:.0%} vs {b2.confidence:.0%})")


if __name__ == "__main__":
    asyncio.run(main())
```

#### 5.4 Conversational Agent (`examples/conversational_agent.py`)

```python
"""Example: Building a conversational agent with memory."""

import asyncio
from uuid import uuid4
from datetime import datetime
from silicon_memory import (
    SiliconMemory,
    Experience,
    RecallContext,
    MemoryTool,
)


class ConversationalAgent:
    """A simple conversational agent with memory.

    This demonstrates how to:
    1. Recall relevant context before responding
    2. Record interactions as experiences
    3. Build up knowledge over time
    """

    def __init__(self, memory: SiliconMemory):
        self.memory = memory
        self.tool = MemoryTool(memory)
        self.session_id = f"session-{datetime.now().strftime('%Y%m%d-%H%M%S')}"
        self.turn_count = 0

    async def process_message(self, user_message: str) -> str:
        """Process a user message and generate a response."""
        self.turn_count += 1

        # =================================================================
        # STEP 1: Recall relevant context
        # =================================================================

        ctx = RecallContext(
            query=user_message,
            max_facts=5,
            max_experiences=3,
            max_procedures=2,
            min_confidence=0.5,
        )
        recall = await self.memory.recall(ctx)

        # Build context string for LLM (in real app, send to LLM)
        context_parts = []

        if recall.facts:
            context_parts.append("Relevant facts:")
            for fact in recall.facts:
                context_parts.append(f"  - {fact.content} ({fact.confidence:.0%})")

        if recall.experiences:
            context_parts.append("Previous interactions:")
            for exp in recall.experiences:
                context_parts.append(f"  - {exp.content}")

        if recall.procedures:
            context_parts.append("Relevant procedures:")
            for proc in recall.procedures:
                context_parts.append(f"  - {proc.content}")

        context = "\n".join(context_parts) if context_parts else "No relevant context found."

        # =================================================================
        # STEP 2: Generate response (placeholder - use LLM in real app)
        # =================================================================

        response = f"[Agent would respond based on context]\n\nContext used:\n{context}"

        # =================================================================
        # STEP 3: Record the interaction as an experience
        # =================================================================

        experience = Experience(
            id=uuid4(),
            content=f"User asked: {user_message[:100]}",
            outcome=f"Responded with context from {len(recall.facts)} facts",
            emotional_valence=0.5,
            importance=0.6,
            session_id=self.session_id,
            sequence_id=self.turn_count,
        )
        await self.memory.record_experience(experience)

        # =================================================================
        # STEP 4: Update working memory with conversation state
        # =================================================================

        await self.memory.set_context("last_query", user_message, ttl_seconds=600)
        await self.memory.set_context("turn_count", self.turn_count, ttl_seconds=600)

        return response

    async def learn_fact(self, subject: str, predicate: str, obj: str, confidence: float = 0.8):
        """Learn a new fact from the conversation."""
        response = await self.tool.invoke(
            action="store_fact",
            subject=subject,
            predicate=predicate,
            object=obj,
            confidence=confidence,
        )
        return response.success


async def main():
    async with SiliconMemory("/tmp/agent_example") as memory:

        agent = ConversationalAgent(memory)

        # Teach the agent some facts
        await agent.learn_fact("Python", "is great for", "beginners")
        await agent.learn_fact("Python", "has", "extensive libraries")

        # Simulate a conversation
        messages = [
            "What can you tell me about Python?",
            "Is it good for beginners?",
            "What about libraries?",
        ]

        for msg in messages:
            print(f"\nðŸ‘¤ User: {msg}")
            response = await agent.process_message(msg)
            print(f"\nðŸ¤– Agent:\n{response}")
            print("-" * 50)


if __name__ == "__main__":
    asyncio.run(main())
```

### Implementation Tasks

| Task | Description | Effort |
|------|-------------|--------|
| 5.1.1 | Create `examples/` directory | S |
| 5.1.2 | Write basic_usage.py | M |
| 5.1.3 | Write llm_tools.py | M |
| 5.1.4 | Write knowledge_base.py | M |
| 5.1.5 | Write conversational_agent.py | M |
| 5.1.6 | Update README with examples | M |
| 5.1.7 | Add docstrings to all public APIs | L |

---

## Phase 6: Testing & Quality (Priority: Medium)

### Tasks

| Task | Description | Effort |
|------|-------------|--------|
| 6.1.1 | Add unit tests for core types | M |
| 6.1.2 | Add property-based tests (hypothesis) | M |
| 6.1.3 | Add benchmarks for performance | M |
| 6.1.4 | Add type checking with mypy | S |
| 6.1.5 | Add linting with ruff | S |
| 6.1.6 | Set up CI/CD pipeline | M |

---

## Implementation Schedule

### Sprint 1 (Week 1-2): Examples & Documentation
- [x] 5.1.1 - 5.1.6: All examples (COMPLETED)
- [ ] 6.1.4 - 6.1.5: Type checking and linting

### Sprint 2 (Week 3-4): Graph Query Layer
- [x] 2.1.1 - 2.1.5: Complete graph module (COMPLETED)

### Sprint 3 (Week 5-6): Reflection Engine
- [x] 1.1.1 - 1.1.4: Core reflection components (COMPLETED)
- [x] 1.1.5 - 1.1.6: Tool and tests (COMPLETED)

### Sprint 4 (Week 7-8): LLM Clients
- [x] 3.1.1 - 3.1.6: OpenAI and Anthropic clients (COMPLETED)

### Sprint 5 (Week 9-10): Polish & Release
- [ ] 6.1.1 - 6.1.3: Testing improvements
- [ ] 6.1.6: CI/CD
- [x] 4.1.x: DSPy integration (COMPLETED)

---

## Success Criteria

### Functional
- [x] All four memory types work end-to-end
- [x] LLM tools work with OpenAI function calling
- [x] Reflection engine extracts beliefs from experiences
- [x] Graph queries return meaningful results
- [x] All examples run successfully

### Non-Functional
- [ ] Recall latency < 100ms for 10K documents
- [ ] Memory usage < 500MB for 100K documents
- [ ] Test coverage > 80%
- [ ] All public APIs documented

### User Experience
- [ ] Clear error messages
- [ ] Intuitive API design
- [ ] Comprehensive examples
- [ ] Getting started in < 5 minutes

---

## Appendix: File Structure (Target)

```
silicon-memory/
â”œâ”€â”€ src/silicon_memory/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ types.py          # Belief, Experience, Procedure, etc.
â”‚   â”‚   â”œâ”€â”€ protocols.py      # Abstract interfaces
â”‚   â”‚   â””â”€â”€ exceptions.py     # Custom exceptions
â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ silicondb_router.py  # SiliconMemory main class
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ silicondb_backend.py  # SiliconDB operations
â”‚   â”œâ”€â”€ temporal/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ clock.py          # System/Fake clock
â”‚   â”‚   â”œâ”€â”€ decay.py          # Confidence decay
â”‚   â”‚   â””â”€â”€ validity.py       # Temporal validation
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ memory_tool.py    # LLM function tool
â”‚   â”‚   â””â”€â”€ query_tool.py     # Query/verification tool
â”‚   â”œâ”€â”€ reflection/           # NEW
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ processor.py      # Experience processor
â”‚   â”‚   â”œâ”€â”€ patterns.py       # Pattern extraction
â”‚   â”‚   â””â”€â”€ generator.py      # Belief generation
â”‚   â”œâ”€â”€ graph/                # NEW
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ queries.py        # Graph query builder
â”‚   â”‚   â””â”€â”€ explorer.py       # Entity exploration
â”‚   â”œâ”€â”€ clients/              # NEW
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py           # Base memory client
â”‚   â”‚   â”œâ”€â”€ openai.py         # OpenAI integration
â”‚   â”‚   â””â”€â”€ anthropic.py      # Anthropic integration
â”‚   â””â”€â”€ dspy/                 # NEW (optional)
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ modules.py        # DSPy modules
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ embedder_cache.py
â”‚   â”œâ”€â”€ test_integration.py
â”‚   â”œâ”€â”€ test_e2e.py
â”‚   â””â”€â”€ test_reflection.py    # NEW
â”œâ”€â”€ examples/                 # NEW
â”‚   â”œâ”€â”€ basic_usage.py
â”‚   â”œâ”€â”€ llm_tools.py
â”‚   â”œâ”€â”€ knowledge_base.py
â”‚   â””â”€â”€ conversational_agent.py
â”œâ”€â”€ specs/
â”‚   â”œâ”€â”€ MemorySystem.tla
â”‚   â”œâ”€â”€ BeliefSystem.tla
â”‚   â”œâ”€â”€ TemporalDecay.tla
â”‚   â””â”€â”€ WorkingMemory.tla
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â””â”€â”€ IMPLEMENTATION_PLAN.md
```
